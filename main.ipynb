{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59937d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and load all concated time series into data #\n",
    "\n",
    "import os\n",
    "import ast\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "vectors = [f for f in os.listdir(path) if (os.path.isfile(os.path.join(path, f)) & f.endswith('.txt'))]\n",
    "print('Reading {0} vectors...'.format(len(vectors)))\n",
    "\n",
    "data = list()\n",
    "\n",
    "useAllFeatures = True;\n",
    "\n",
    "for r in vectors:\n",
    "    rPath = path + \"/\" + r\n",
    "    name = r.split('.', 1)[0]\n",
    "\n",
    "    saveFile = open(name + '.txt', 'r')\n",
    "    line = saveFile.read()\n",
    "    saveFile.close()\n",
    "    \n",
    "    if useAllFeatures:\n",
    "        multivec = ast.literal_eval(line)\n",
    "        # concatenating the vectors for different features into one long vector. As each feature has the same length within a single point, they should all be scaled equally\n",
    "        vec =[*multivec[0], *multivec[1], *multivec[2], *multivec[3], *multivec[4], *multivec[5]];\n",
    "        data.append(vec);\n",
    "    else:\n",
    "        # testing option for single feature\n",
    "        data.append(ast.literal_eval(line)[0]);\n",
    "    \n",
    "path = os.getcwd() + '\\\\samples'\n",
    "\n",
    "# Here we get additional samples from /samples/ subdir to validate clustering\n",
    "# Remove this if no samples\n",
    "vectors = [f for f in os.listdir(path) if (os.path.isfile(os.path.join(path, f)) & f.endswith('.txt'))]\n",
    "print('Reading {0} additional samples...'.format(len(vectors)))\n",
    "samples = list()\n",
    "sampleNames = list()\n",
    "for r in vectors:\n",
    "    rPath = path + \"\\\\\" + r\n",
    "    name = r.split('.', 1)[0]\n",
    "\n",
    "    saveFile = open(rPath, 'r')\n",
    "    line = saveFile.read()\n",
    "    saveFile.close()\n",
    "    \n",
    "    multivec = ast.literal_eval(line)\n",
    "    # concatenating the vectors for different features into one long vector. As each feature has the same length within a single point, they should all be scaled equally\n",
    "    vec =[*multivec[0], *multivec[1], *multivec[2], *multivec[3], *multivec[4], *multivec[5]];\n",
    "    samples.append(vec);\n",
    "    sampleNames.append(name)\n",
    "\n",
    "print(sampleNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f59c180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "# from tslearn.datasets import CachedDatasets\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance, \\\n",
    "    TimeSeriesResampler\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a585266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling the vectors (scaling, interpolation) to fit all runs into a n-d vector\n",
    "n = 100\n",
    "X_train = TimeSeriesResampler(sz=n).fit_transform(data)\n",
    "sz = X_train.shape[1]\n",
    "\n",
    "scaled_samples = TimeSeriesResampler(sz=n).fit_transform(samples)\n",
    "\n",
    "seed = 0\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9812575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means and graph #\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "troops = [\"drones\", \"zerglings\", \"roaches\", \"hydralisks\", \"mutalisks\", \"banelings\"];\n",
    "dmetric = \"softdtw\"\n",
    "clustercount = 3;\n",
    "\n",
    "km = TimeSeriesKMeans(n_clusters=clustercount,\n",
    "                           metric=dmetric,\n",
    "                           # metric_params={\"gamma\": .01},\n",
    "                           verbose=False,\n",
    "                           random_state=seed,\n",
    "                           n_jobs=-1)\n",
    "y_pred = km.fit_predict(X_train)\n",
    "\n",
    "plt.figure(dpi=1200)\n",
    "\n",
    "# Render a graph for each cluster\n",
    "for yi in range(clustercount):\n",
    "    \n",
    "    # Graph layout\n",
    "    plt.subplot(int(clustercount / 3) + 1, 3, 1 + yi)\n",
    "    # Select the cluster from the data\n",
    "    for xx in X_train[y_pred == yi]:\n",
    "        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "    # Plot the mean\n",
    "    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "    plt.xlim(0, sz)\n",
    "    plt.xticks(numpy.arange(0, sz, sz / 6), [])\n",
    "    plt.ylim(0, 50)\n",
    "    plt.text(0.55, 0.85,'Cluster %d' % (yi + 1),\n",
    "             transform=plt.gca().transAxes)\n",
    "    if yi == 1:\n",
    "        plt.title(\"Troops over game time(\" + \", \".join(troops) + \")\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cluster.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dbcb531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"base baneling bust\" is in cluster 1\n",
      "\"muta ling bane\" is in cluster 1\n",
      "\"roach hydra\" is in cluster 1\n",
      "\"roach nydus\" is in cluster 3\n",
      "\"zergling baneling\" is in cluster 2\n",
      "\"zergling muta\" is in cluster 1\n"
     ]
    }
   ],
   "source": [
    "# test clusters against each additional sample\n",
    "clustered_samples = km.predict(scaled_samples)\n",
    "i = 0\n",
    "for name in sampleNames:\n",
    "    print('\"{0}\" is in cluster {1}'.format(name, clustered_samples[i] + 1))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd4964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration used in video. Irrelevant to paper #\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "lol = [km.cluster_centers_[0].ravel()];\n",
    "a = TimeSeriesResampler(sz=140).fit_transform(lol)[0];\n",
    "a = [x+50 for x in a]\n",
    "b = km.cluster_centers_[1].ravel();\n",
    "b = TimeSeriesResampler(sz=140).fit_transform(b)[0];\n",
    "b = [x+2 for x in b]\n",
    "plt.figure(dpi=1200)\n",
    "plt.plot(a, 'b-')\n",
    "plt.plot(b, 'r-')\n",
    "plt.xlim(0, 140)\n",
    "plt.yticks(numpy.arange(0, 150, 50), [])\n",
    "plt.xticks([])\n",
    "plt.yticks()\n",
    "plt.ylim(0, 120)\n",
    "plt.title(\"After resampling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b54ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding optimal K #\n",
    "\n",
    "from tslearn.metrics import cdist_dtw\n",
    "import tslearn.clustering\n",
    "scores = list()\n",
    "dmetric = \"softdtw\"\n",
    "def kmeans(clustercount):\n",
    "    global scores\n",
    "    km = TimeSeriesKMeans(n_clusters=clustercount,\n",
    "                           metric=dmetric,\n",
    "                           # metric_params={\"gamma\": .01},\n",
    "                           verbose=False,\n",
    "                           random_state=seed,\n",
    "                           n_jobs=-1)\n",
    "    clstrs = km.fit_predict(X_train)\n",
    "\n",
    "    sil = tslearn.clustering.silhouette_score(X_train, clstrs, metric=\"softdtw\", n_jobs=-1)\n",
    "    print(\"(k, sil) = ({0}, {1:.4f})\".format(clustercount,sil))\n",
    "    scores.append(sil)\n",
    "\n",
    "krange = range(2, 9)\n",
    "for k in krange:\n",
    "    kmeans(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63c1aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing k vs silscore #\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k = range(2, 9)\n",
    "scores = [0.498, 0.510, 0.420, 0.441, 0.414, 0.400, 0.357]\n",
    "\n",
    "print(\"(k, sil) = ({0}, {1:.4f})\".format(2,scores[0]))\n",
    "plt.figure(dpi=1200)\n",
    "plt.xlim(0, 9)\n",
    "plt.ylim(0, 0.6)\n",
    "plt.plot(k, scores)\n",
    "plt.scatter(k, scores)\n",
    "\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"silhouette\")\n",
    "plt.title(\"K-means Cluster Count vs Silhouette Score\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
